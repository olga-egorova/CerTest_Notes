---
title: "Cantilever beam: single beam inference, non-isotropic error"
author: "Olga Egorova"
date: "`r format(Sys.time(), '%d %B %Y')`"
output: 
  html_document:
    df_print: paged
header-includes: \usepackage{bm}
---

Toy example. Cantilever beam

We consider here a 3-layer beam with 2 interfaces, clamped at one end, with no extra load -- just gravity.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = "")  # set the wd
```

```{r warning=FALSE}
library(data.table)
library(ggplot2)
library(rstan)
```

```{r include=FALSE, echo = FALSE}
# Set up of venv/python scripts path
library(reticulate)
use_virtualenv("/Users/olga/anaconda3/envs/pyComp")  
python_data = "/Users/olga/work/CerTest/pyComp/examples/cantilever_data.py"
python_sim  = "/Users/olga/work/CerTest/pyComp/examples/cantilever_sim.py"
```

Data generation. 

We start with assuming normal independent errors with zero mean and variance $\sigma^2_e$. The variance is constant across the observational points -- it is attributed to the variability occurring from the observational process rather than from the location of the points or any other properties.

Displacement values are non-positive, so that adding an error should not result in generated negative values. So we shall write the model for the log-transformed response and forward model output, with normal i.i.d. errors:
$$ \log(-d^{(i)}) = \log(-F(\xi)) + \varepsilon_{i}.$$
Then $d^{(i)} = F(\xi)\times \exp(\varepsilon_{i}).$

Setting up the parameters
```{r}
n_beam = 1            # number of "true" underlying theta-s
n_data = 100          # number of observational points from each beam
n_simulations = 30    # number of simulations to be run

n_sim_points = 10     # number of locations to be chosen per simulation run

error_scale = 5*10^(-3)  # artificial data -- added error is scaled w.r.t. the FEM-displacement
#sigma_e = 10^(-8) ; sigma2_e = sigma_e^2  # constant measurement error variance for data generation
```

I.  Data

Picking the "true" theta-s, running the FE model and saving the displacements.
If no python code is run -- please go straight to the next chunk.

```{r}
# Choosing the true theta within the region of -/+(pi/30)
theta_data = data.table(matrix(runif(n = 3*n_beam, min = -pi/30, max = pi/30), nrow = n_beam))
colnames(theta_data) = c("theta_1", "theta_2", "theta_3")
theta_data
theta_data*180/pi

############################################
# Load the FE model for data generation
############################################
source_python(python_data)
dt_coords = read.table("out/obs_coords.csv", header = FALSE, sep = ",",  col.names = c("x", "y", "z"))

# Obtain displacements across all observational points
dt_displacements = cbind(dt_coords, data.frame("D" = rep(0, nrow(dt_coords))))
for (d in 1:n_beam){
 dt_displacements[, ncol(dt_coords)+d] = 
   myModel$solve(baseAngles + as.numeric(theta_data[d,]), TRUE, iterativeSolver = FALSE)
}

write.csv(theta_data, "out/theta_data.csv", row.names = FALSE)
write.csv(dt_displacements, "out/dt_displacements.csv", row.names = FALSE)
```

Read the "true" $\theta$-s and the displacement values
```{r}
theta_data = read.table("out/theta_data.csv", header = TRUE, sep = ",")
dt_data_coords = read.table("out/obs_coords.csv", header = FALSE, sep = ",", 
                            col.names = c("x", "y", "z"))
dt_displacements = read.table("out/dt_displacements.csv", header = TRUE, sep = ",")
n_beam = nrow(theta_data)

dt_displacements$logD = log(-dt_displacements$D)

# Generate artificial data: additive errors with variances proportional to the displacements
dt_displacements$data = dt_displacements$logD + rnorm(nrow(dt_displacements), mean = 0, 
                                                      sd = error_scale*abs(dt_displacements$D))
dt_displacements

# Choose observational points:
coords_ind = sort(maximin::maximin.cand(n = n_data, Xcand = as.matrix(dt_data_coords))$inds)  # c(1:3,5:11)
dt_data = dt_displacements[coords_ind, c(1:3, ncol(dt_displacements))]

coords_ind[which(dt_data$data == "-Inf")] = coords_ind[which(dt_data$data == "-Inf")] + 1
dt_data = dt_displacements[coords_ind, c(1:3, ncol(dt_displacements))]

write.csv(dt_data, "out/dt_data.csv", row.names = FALSE)
```

II. Simulations

Running the simulations: choosing $\theta$-s as a space-filling design from a "feasible" region: $\pm \pi/30$.
If no python code is run -- please go to the next chunk.
```{r}
#########################################
# Choose theta values for simulation
#########################################
mogp_emulator = import("mogp_emulator")
theta_interval = tuple(-pi/30, pi/30, convert = TRUE)
theta_design = mogp_emulator$LatinHypercubeDesign(list(theta_interval, theta_interval, theta_interval))
theta_simulation = theta_design$sample(n_simulations)
colnames(theta_simulation) = c("theta_1", "theta_2", "theta_3")

#########################################
# Load the FE model for simulations
#########################################
source_python(python_sim)
n_sim_coords = length(myModel$tmp)   

dt_all_simulation = matrix(0, ncol = n_simulations, nrow = n_sim_coords)
# running the simulations
for (p in 1:n_simulations){
  dt_all_simulation[,p] = myModel$solve(baseAngles + theta_simulation[p,], TRUE, iterativeSolver = FALSE)
}

write.csv(theta_simulation, "out/theta_simulation.csv", row.names = FALSE)
write.csv(dt_all_simulation, "out/dt_all_simulation.csv", row.names = FALSE)
```


Read the simulation output for all the observational points.

```{r}
dt_all_simulation = read.table("out/dt_all_simulation.csv", header = TRUE, sep = ",")
dt_log_simulation = log(-dt_all_simulation)

dt_sim_coords = read.table("out/sim_coords.csv", header = FALSE, sep = ",",
                           col.names = c("x", "y", "z"))  # coordinates of the simulation points
theta_simulation = read.table("out/theta_simulation.csv", header = TRUE, sep = ",")

# Simulations to be considered: choosing the observational points  (#TBD in a more robust way)

X_sim =  matrix(nrow = 0, ncol = ncol(dt_sim_coords))
XT_sim = matrix(nrow = 0, ncol = ncol(dt_sim_coords) + ncol(theta_simulation))
simulation = c()
for (i in 1:n_simulations) {
  sim_ind = sort(maximin::maximin.cand(n = n_sim_points, Xcand = as.matrix(dt_sim_coords))$inds)
  
  cur_sim = dt_log_simulation[sim_ind, i]
  faulty_ind = which(cur_sim == "-Inf"); sim_ind[faulty_ind] = sim_ind[faulty_ind] + 2
  faulty_ind = which(is.nan(cur_sim)); sim_ind[faulty_ind] = sim_ind[faulty_ind] + 1
  cur_sim = dt_log_simulation[sim_ind,i]

  simulation = c(simulation, cur_sim)
  # X_sim -- location parameters of the simulations
  X_sim = dt_sim_coords[sim_ind, 1:ncol(dt_sim_coords)]
  XT_sim = rbind(XT_sim, cbind(as.matrix(X_sim), 
                               matrix(rep(as.vector(theta_simulation[i,]), n_sim_points), 
                                      byrow = TRUE, nrow = n_sim_points)))
}

#colnames(XT_sim) = c(colnames(dt_sim_coords), colnames(theta_simulation))

# all in one table
dt_simulation = cbind(XT_sim, matrix(simulation, ncol = 1))
colnames(dt_simulation) = c(colnames(dt_sim_coords), colnames(theta_simulation), "s")

dt_simulation
write.csv(dt_simulation, "out/dt_simulation.csv", row.names = FALSE)
```

In case the previous chunk is not run -- read the simulation inputs and outputs 
```{r}
dt_simulation = read.table("out/dt_simulation.csv", header = TRUE, sep = ",")
XT_sim = dt_simulation[,1:(ncol(dt_simulation) -1)]
```  

The following sets up the rstan environment, and the parameters for the stan model

```{r}
## Set up the environment
## https://betanalpha.github.io/assets/case_studies/gaussian_processes.html#21_Simulating_From_A_Gaussian_Process

# set stan to execute multiple Markov chains in parallel
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
parallel:::setDefaultClusterOptions(setup_strategy = "sequential")

util = new.env()
par(family="CMU Serif", las=1, bty="l", cex.axis=1, cex.lab=1, cex.main=1,
    xaxs="i", yaxs="i", mar = c(5, 5, 3, 5))

## https://github.com/adChong/bc-stan/blob/master/src/main.R

# get dimensions of dataset
p = ncol(dt_data_coords)     # number of input factors
q = ncol(XT_sim) - p    # number of calibration parameters
n = nrow(dt_data)       # sample size of observed field data
m = nrow(XT_sim)        # sample size of computer simulation data

# extract data from DATAFIELD (Table 3) and DATACOMP (Table 4) 
y = dt_data[,p+1]                   # observed output
eta = dt_simulation[,p+q+1]         # simulation output
xf = dt_data[,1:p]                  # observed input
xc = as.matrix(XT_sim[, 1:p])       # simulation input
tc = as.matrix(XT_sim[,(p+1):(p+q)])       # calibration parameters input

x_pred = xf                     # design points for predictions
n_pred = nrow(x_pred)           # number of predictions

# standardisation of output y and eta w.r.t eta
eta_mu = mean(eta, na.rm = TRUE) # mean value
eta_sd = sd(eta, na.rm = TRUE)   # standard deviation
eta = (eta - eta_mu) / eta_sd

y_mu = mean(y, na.rm = TRUE) # mean value
y_sd = sd(y, na.rm = TRUE)   # standard deviation
y = (y - eta_mu) / eta_sd

# Put design points xf and xc on [0,1]
x = rbind(as.matrix(xf), as.matrix(xc))
for (i in (1:ncol(x))){
  x_min = min(x[,i], na.rm = TRUE)
  x_max = max(x[,i], na.rm = TRUE)
  xf[,i] = (xf[,i] - x_min) / (x_max - x_min)
  xc[,i] = (xc[,i] - x_min) / (x_max - x_min)
  x_pred[,i] = (x_pred[,i] - x_min) / (x_max - x_min)
}

# Put calibration parameters t on domain [0,1]
for (j in (1:ncol(tc))){
  tc_min = min(tc[,j], na.rm = TRUE)
  tc_max = max(tc[,j], na.rm = TRUE)
  tc[,j] = (tc[,j] - tc_min) / (tc_max - tc_min)
}

# create data as list for input to Stan
stan_data = list(n=n, m=m, n_pred=n_pred, p=p, y=y, q=q, eta=eta, 
                  xf=as.matrix(xf), xc=as.matrix(xc), 
                  x_pred=as.matrix(x_pred), tc=as.matrix(tc))
```

Fit a model with the discrepancy term
```{r}
# run model in stan
fit = stan(file = "Bayesian_calibration_GPs.stan",
           data = stan_data,
           iter = 4000,
           chains = 3)

# plot traceplots, excluding warm-up
stan_trace(fit, pars = c("mu", "tf", "cl2_eta_inv", "cl2_delta_inv", 
                         "lambda_eta", "lambda_delta", "lambda_e"))  #"mu", 

# summarize results
print(fit, pars = c("mu", "tf", "cl2_eta_inv", "cl2_delta_inv", 
                    "lambda_eta", "lambda_delta", "lambda_e"))

# posterior probability distribution of tf
stan_hist(fit, pars = c("tf"))
stan_hist(fit, pars = c("mu"))

```


```{r}
# True scaled theta-s
c((theta_data[1,1]- min(XT_sim[,p+1]))/(max(XT_sim[,p+1]) - min(XT_sim[,p+1])),
  (theta_data[1,2]- min(XT_sim[,p+2]))/(max(XT_sim[,p+2]) - min(XT_sim[,p+2])),
  (theta_data[1,3]- min(XT_sim[,p+3]))/(max(XT_sim[,p+3]) - min(XT_sim[,p+3])))

theta_data/(pi/180)
```


Look at pairs and triplets of theta posteriors -- in contrast with marginals observed on the histograms before
```{r}
df_of_draws = as.data.table(fit)               # nrow == number of chains x number of iterations
setnames(df_of_draws, old = c("tf[1]", "tf[2]", "tf[3]"),
         new = c("tf1", "tf2", "tf3"))
head(df_of_draws)

#hexbin::hexbinplot(tf2~tf1, data=df_of_draws, mincnt=2, maxcnt=20)
library(MASS)

# par()    #change plotting parameters
par(cex.axis = 0.5)
k1 <- kde2d(df_of_draws$tf1, df_of_draws$tf2, n=100)
image(k1, xlab = expression(theta[1]), ylab = expression(theta[2]))
# Adjust binning (interpolate - can be computationally intensive for large datasets)
k2 <- kde2d(df_of_draws$tf3, df_of_draws$tf2, n=100)
image(k2, xlab = expression(theta[3]), ylab = expression(theta[2]))

k3 <- kde2d(df_of_draws$tf1, df_of_draws$tf3, n=100)
image(k3, xlab = expression(theta[1]), ylab = expression(theta[3]))

```

Run model without the discrepancy term

```{r}
# run model in stan
fit0 = stan(file = "Calibration_GPs_no_discrepancy.stan",
           data = stan_data,
           iter = 4000,
           chains = 3)

# plot traceplots, excluding warm-up
stan_trace(fit0, pars = c("mu","tf", "cl2_eta_inv", 
                         "lambda_eta", "lambda_e"))  #"mu", 

# summarize results
print(fit0, pars = c("mu","tf", "cl2_eta_inv", 
                    "lambda_eta", "lambda_e"))

# posterior probability distribution of tf
stan_hist(fit0, pars = c("tf"))
stan_hist(fit0, pars = c("mu"))
```

Pair-wise plots for the model without the discrepancy term:
```{r}
df_of_draws0 = as.data.table(fit0)               # nrow == number of chains x number of iterations
setnames(df_of_draws0, old = c("tf[1]", "tf[2]", "tf[3]"),
         new = c("tf1", "tf2", "tf3"))

par(cex.axis = 0.5)
k10 <- kde2d(df_of_draws0$tf1, df_of_draws0$tf2, n=100)
image(k10, xlab = expression(theta[1]), ylab = expression(theta[2]))
k20 <- kde2d(df_of_draws0$tf3, df_of_draws0$tf2, n=100)
image(k20, xlab = expression(theta[3]), ylab = expression(theta[2]))
k30 <- kde2d(df_of_draws0$tf1, df_of_draws0$tf3, n=100)
image(k30, xlab = expression(theta[1]), ylab = expression(theta[3]))
```



